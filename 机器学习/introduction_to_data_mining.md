# 数据挖掘导论

数据挖掘是在大型数据存储库中，自动地发现有用信息的过程。

# 数据

## 数据预处理

### 聚集

**聚集**(aggregation)将两个或多个对象合并成单个对象。考虑一个由事务（数据对象）组成的数据集，它记录一年中不同日期在各地商店的商品日销售情况。对该数据集的事务进行聚集的一种方法是用一个商店事务替换该商店的所有事务（groupby）。具有如下作用：

- 数据规约导致的较小数据集需要较少的内存和处理时间，因此可以使用开销更大的数据挖掘算法。
- 通过高层而不是低层数据视图，聚集起到了范围或标度转换的作用。
- 相对于被聚集的单个对象，诸如平均值、总数等聚集量具有较小的变异性。

### 抽样

抽样是一种选择数据对象子集进行分析的常用方法。

抽样方法：

- 简单随机抽样,分为无放回抽样和有放回抽样。
- 分层抽样：当每种类型的对象数量差别很大时，简单随机抽样不能充分地代表不太频繁出现的对象类型，故可使用分层抽样。
- 渐近抽样：合适的样本容量可能很难确定，因此需要自适应或渐近抽样方法。这些方法从一个小样本开始，然后增加样本容量直至得到足够容量的样本。例如使用渐近抽样来学习一个预测模型，尽管预测模型的准确率随样本容量增加，但是在某一点准确率的增加趋于稳定，我们希望在稳定点停止增加样本容量。

### 维归约

- 如果纬度（数据属性个数）较低，许多数据挖掘算法的效果就会更好。维归约可以删除不相关的特征并降低噪声。
- 维归约可以使模型更容易理解。

#### 维灾难

随着数据纬度的增加，数据在它所占据的空间中越来越稀疏。

#### 维归约的线性代数技术

维归约的一些最常用的方法是使用线性代数技术，将数据由高维空间投影到低维空间。

- 主成分分析：是一种用于连续属性的线性代数技术，它找出新的属性（主成分），这些属性是原属性的线性组合，是相互正交的，并且捕获了数据的最大变差。
- 奇异值分解

#### 特征子集选择

- 嵌入方法：决策树分类器通常以这种方式运行。
- 过滤方法：使用独立于数据挖掘任务的方法，在数据挖掘算法运行前进行特征选择，例如我们可以选择属性集合，它的属性对之间的相关度尽可能低。
- 包装方法：类似于穷举各种特征集合，通过数据挖掘算法进行效果验证。

#### 离散化和二元化

- 二元化：one hot或者直接one label
- 连续属性离散化：将连续属性值排序后，通过指定$$n-1$$个分割点把它们分成$$n$$个区间。
- 非监督离散化：用于分类的离散化方法之间的根本区别在于使用类信息（监督）还是不使用类信息（非监督）。如果不使用类信息，则可以使用等宽（可能受离群点的影响而性能不佳）、等频率、等深。
- 监督离散化：开始将初始值切分成两部分，让两个结果区间产生最小熵。然后取一个区间，通常选取最大熵区间，重复此分割过程，直到区间的个数达到用户指定的个数。
- 具有过多值的分类属性：如果分类属性是序数属性，则可以使用类似于处理连续属性的技术，如果是标称的，就需要使用其他办法。

#### 变量变换

- 简单函数：logx、1/x等
- 规范化或标准化

# 异常检测

异常检测的目标是发现与大部分其他对象不同的对象。

## 异常检测方法

- 基于模型的技术：如果一个对象不能很好地同该模型拟合，即如果它很可能不服从该分布，则它是一个异常。在某些情况下很难建立模型，例如，因为数据的统计分布未知或没有训练数据可用，这种情况下可用使用不需要模型的技术。
- 基于邻近度的技术：通常可用在对象之间定义邻近性度量，并且许多异常检测方法都基于邻近度。异常对象是那些远离大部分其他对象的对象。
- 基于密度的技术：对象的密度估计可以相对直接地计算，特别是当对象之间存在邻近性度量时，低密度区域中的对象相对远离近邻，可能被看作异常。一种更复杂的方法考虑到数据集可能有不同密度区域这一事实，仅当一个点的局部密度显著地低于它的大部分近邻时才将其分类为离群点。